---
category: 'Data Analysis'
tags: ['Classification']
title: "[실습] 불균형 데이터 처리 기법 비교 (Kaggle - Credit Card Fraud Detection)"
---

> CatBoost는 하이퍼파라미터를 크게 신경쓰지 않아도 된다고 하여, CatBoost를 사용했다.
>
> 하지만 어떤 분류기를 쓰는지 또 어떤 데이터인지에 따라 결과는 다 다르다.

데이터 : [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)

<br>

### 비교 대상

- 원본 데이터
- SMOTE
- ADASYN
- SVMSMOTE
- CNN
- Near Miss 3
- SMOTE + ENN
- ADASYN + ENN
- SVMSMOTE + ENN
- SMOTE + IHT
- ADASYN + IHT
- SVMSMOTE + IHT
- Inverse Class Frequency (Balanced)
- Inverse Square Root of Class Frequency (SqrtBalanced)

> 사용한 데이터에는 `Tomek Link`쌍이 없어서, 제거되는 데이터가 없었기 때문에 비교 목록에서 제외하였다.

<br>

```python
import pandas as pd
import numpy as np
from catboost import CatBoostClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report
from matplotlib import pyplot as plt
import seaborn as sns
```


```python
pd.set_option("display.max_columns", None)
```

<br>


## 데이터

> Resampling은 따로 진행하였으며, `pickle`을 이용해 저장한 후 사용하였다.
>
> 샘플링 방법은 [불균형 데이터 처리 기법 - Resampling](/data%20analysis/2021/03/01/Imbalanced-Data-Resampling.html) 포스팅에 정리해 두었다.

```python
X_test.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>V11</th>
      <th>V12</th>
      <th>V13</th>
      <th>V14</th>
      <th>V15</th>
      <th>V16</th>
      <th>V17</th>
      <th>V18</th>
      <th>V19</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>201810</th>
      <td>0.579847</td>
      <td>-0.011862</td>
      <td>1.035499</td>
      <td>-0.317540</td>
      <td>0.216728</td>
      <td>1.201270</td>
      <td>-0.537323</td>
      <td>1.319719</td>
      <td>-0.189181</td>
      <td>-0.627079</td>
      <td>-0.131042</td>
      <td>0.186976</td>
      <td>0.428736</td>
      <td>-0.650821</td>
      <td>0.607427</td>
      <td>-1.605008</td>
      <td>-0.426110</td>
      <td>-0.604022</td>
      <td>0.099792</td>
      <td>0.000011</td>
      <td>-0.286629</td>
      <td>0.166828</td>
      <td>0.550873</td>
      <td>-0.323683</td>
      <td>-0.402491</td>
      <td>0.195611</td>
      <td>-0.573086</td>
      <td>-0.079200</td>
      <td>0.015847</td>
      <td>-0.254035</td>
    </tr>
    <tr>
      <th>264506</th>
      <td>0.901937</td>
      <td>2.267601</td>
      <td>-1.634754</td>
      <td>-2.368609</td>
      <td>-2.592182</td>
      <td>1.161092</td>
      <td>3.434814</td>
      <td>-1.615728</td>
      <td>0.797080</td>
      <td>-1.404452</td>
      <td>1.591339</td>
      <td>-0.219360</td>
      <td>-0.722225</td>
      <td>0.316331</td>
      <td>-0.203926</td>
      <td>0.188359</td>
      <td>-0.707386</td>
      <td>0.435844</td>
      <td>-0.286008</td>
      <td>-0.261407</td>
      <td>-0.343678</td>
      <td>-0.163936</td>
      <td>-0.078568</td>
      <td>0.259323</td>
      <td>0.687408</td>
      <td>-0.131926</td>
      <td>-0.141368</td>
      <td>0.026772</td>
      <td>-0.055990</td>
      <td>0.041920</td>
    </tr>
    <tr>
      <th>63736</th>
      <td>-0.397573</td>
      <td>1.118301</td>
      <td>-1.260762</td>
      <td>0.981093</td>
      <td>-0.380698</td>
      <td>-1.876228</td>
      <td>-0.490142</td>
      <td>-1.089500</td>
      <td>0.062601</td>
      <td>0.119233</td>
      <td>0.495179</td>
      <td>-0.818852</td>
      <td>-1.269072</td>
      <td>-1.259742</td>
      <td>-0.383677</td>
      <td>0.541024</td>
      <td>1.271092</td>
      <td>0.402624</td>
      <td>-0.814504</td>
      <td>0.430227</td>
      <td>0.227343</td>
      <td>0.364685</td>
      <td>0.773901</td>
      <td>-0.193256</td>
      <td>0.415118</td>
      <td>0.360261</td>
      <td>-0.054869</td>
      <td>0.016690</td>
      <td>0.043857</td>
      <td>1.553832</td>
    </tr>
    <tr>
      <th>241327</th>
      <td>0.778757</td>
      <td>2.063018</td>
      <td>0.608260</td>
      <td>-3.168853</td>
      <td>0.618313</td>
      <td>1.228515</td>
      <td>-1.367266</td>
      <td>0.683151</td>
      <td>-0.308130</td>
      <td>-0.147176</td>
      <td>-0.859443</td>
      <td>1.672501</td>
      <td>0.060919</td>
      <td>-0.917332</td>
      <td>-2.099999</td>
      <td>-0.637629</td>
      <td>0.540038</td>
      <td>1.976581</td>
      <td>1.105321</td>
      <td>-0.025014</td>
      <td>-0.155587</td>
      <td>-0.022321</td>
      <td>0.076885</td>
      <td>-0.042470</td>
      <td>0.578092</td>
      <td>0.345450</td>
      <td>0.660782</td>
      <td>-0.089294</td>
      <td>-0.023863</td>
      <td>-0.296793</td>
    </tr>
    <tr>
      <th>271841</th>
      <td>0.940836</td>
      <td>-1.212528</td>
      <td>0.730185</td>
      <td>1.549615</td>
      <td>-0.954037</td>
      <td>0.008643</td>
      <td>-0.092019</td>
      <td>0.124386</td>
      <td>0.595537</td>
      <td>-0.570630</td>
      <td>-1.090583</td>
      <td>0.339272</td>
      <td>0.843626</td>
      <td>0.394601</td>
      <td>0.266667</td>
      <td>-0.512564</td>
      <td>0.792514</td>
      <td>-0.751414</td>
      <td>0.277571</td>
      <td>0.372448</td>
      <td>-0.012042</td>
      <td>-0.161695</td>
      <td>-0.744489</td>
      <td>-0.173554</td>
      <td>-0.405409</td>
      <td>0.217600</td>
      <td>0.357895</td>
      <td>-0.143519</td>
      <td>-0.050795</td>
      <td>0.034654</td>
    </tr>
  </tbody>
</table>
</div>


```python
y_test.head()
```

    201810    0
    264506    0
    63736     0
    241327    0
    271841    0
    Name: Class, dtype: int64

```python
for key, sample in X_samples.items():
    y = y_samples[key]
    total = len(y)
    counts = y.value_counts()

    print('=' * 50)
    print(key)
    print('=' * 50)
    print(f'X : {sample.shape}')
    print('-' * 50)
    print(counts)
    print('-' * 30)
    print(f"Total : {total}")
    for idx in counts.index:
        print(f"{idx} 비율 : {counts[idx] / total * 100:6.2f} %")
    print('=' * 50)
```

    ==================================================
    Raw
    ==================================================
    X : (227845, 30)
    --------------------------------------------------
    0    227447
    1       398
    Name: Class, dtype: int64
    ------------------------------
    Total : 227845
    0 비율 :  99.83 %
    1 비율 :   0.17 %
    ==================================================
    ==================================================
    SMOTE
    ==================================================
    X : (454894, 30)
    --------------------------------------------------
    0    227447
    1    227447
    Name: Class, dtype: int64
    ------------------------------
    Total : 454894
    0 비율 :  50.00 %
    1 비율 :  50.00 %
    ==================================================
    ==================================================
    ADASYN
    ==================================================
    X : (454900, 30)
    --------------------------------------------------
    1    227453
    0    227447
    Name: Class, dtype: int64
    ------------------------------
    Total : 454900
    1 비율 :  50.00 %
    0 비율 :  50.00 %
    ==================================================
    ==================================================
    SVMSMOTE
    ==================================================
    X : (454894, 30)
    --------------------------------------------------
    0    227447
    1    227447
    Name: Class, dtype: int64
    ------------------------------
    Total : 454894
    0 비율 :  50.00 %
    1 비율 :  50.00 %
    ==================================================
    ==================================================
    CNN
    ==================================================
    X : (1306, 30)
    --------------------------------------------------
    0    908
    1    398
    Name: Class, dtype: int64
    ------------------------------
    Total : 1306
    0 비율 :  69.53 %
    1 비율 :  30.47 %
    ==================================================
    ==================================================
    Near Miss 3
    ==================================================
    X : (741, 30)
    --------------------------------------------------
    1    398
    0    343
    Name: Class, dtype: int64
    ------------------------------
    Total : 741
    1 비율 :  53.71 %
    0 비율 :  46.29 %
    ==================================================
    ==================================================
    SMOTE + ENN
    ==================================================
    X : (454503, 30)
    --------------------------------------------------
    1    227447
    0    227056
    Name: Class, dtype: int64
    ------------------------------
    Total : 454503
    1 비율 :  50.04 %
    0 비율 :  49.96 %
    ==================================================
    ==================================================
    ADASYN + ENN
    ==================================================
    X : (454509, 30)
    --------------------------------------------------
    1    227453
    0    227056
    Name: Class, dtype: int64
    ------------------------------
    Total : 454509
    1 비율 :  50.04 %
    0 비율 :  49.96 %
    ==================================================
    ==================================================
    SVMSMOTE + ENN
    ==================================================
    X : (454671, 30)
    --------------------------------------------------
    1    227407
    0    227264
    Name: Class, dtype: int64
    ------------------------------
    Total : 454671
    1 비율 :  50.02 %
    0 비율 :  49.98 %
    ==================================================
    ==================================================
    SMOTE + IHT
    ==================================================
    X : (454894, 30)
    --------------------------------------------------
    0    227447
    1    227447
    Name: Class, dtype: int64
    ------------------------------
    Total : 454894
    0 비율 :  50.00 %
    1 비율 :  50.00 %
    ==================================================
    ==================================================
    ADASYN + IHT
    ==================================================
    X : (454894, 30)
    --------------------------------------------------
    0    227447
    1    227447
    Name: Class, dtype: int64
    ------------------------------
    Total : 454894
    0 비율 :  50.00 %
    1 비율 :  50.00 %
    ==================================================
    ==================================================
    SVMSMOTE + IHT
    ==================================================
    X : (454894, 30)
    --------------------------------------------------
    0    227447
    1    227447
    Name: Class, dtype: int64
    ------------------------------
    Total : 454894
    0 비율 :  50.00 %
    1 비율 :  50.00 %
    ==================================================

<br>


## CatBoost


```python
def show_data_info(y):
    total = len(y)
    counts = y.value_counts()
    print('=' * 80)
    print(counts)
    print('-' * 30)
    for idx in counts.index:
        print(f"{idx} 비율 : {counts[idx] / total * 100:6.2f} %")
    print('=' * 80)

def evaluate_model(clf, x_test, y_test):
    y_proba = clf.predict_proba(x_test)
    y_pred = clf.predict(x_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    fl = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_proba[:, 1])

    print('=' * 80)
    print('Confusion Matrix')
    print(confusion_matrix(y_test, y_pred))
    print('-' * 60)
    print(f'Accuracy  : {accuracy}')
    print(f'Precision : {precision}')
    print(f'Recall    : {recall}')
    print(f'F1-Score  : {fl}')
    print('-' * 60)
    print(classification_report(y_test,y_pred))
    print('-' * 60)
    print(f'ROC AUC : {roc_auc}')
    print('=' * 80)

    return accuracy, precision, recall, fl, roc_auc
```


```python
clfs, results = {}, {}

for key, X in X_samples.items():
    y = y_samples[key]

    print('=' * 80)
    print(key)
    show_data_info(y)

    clf = CatBoostClassifier(eval_metric='F1', early_stopping_rounds=100, verbose=False)
    clf.fit(X, y, eval_set=(X_test, y_test))

    print(f'CatBoost {key}')
    result = evaluate_model(clf, X_test, y_test)

    clfs[key] = clf
    results[key] = result
```

    ================================================================================
    Raw
    ================================================================================
    0    227447
    1       398
    Name: Class, dtype: int64
    ------------------------------
    0 비율 :  99.83 %
    1 비율 :   0.17 %
    ================================================================================
    CatBoost Raw
    ================================================================================
    Confusion Matrix
    [[56865     3]
     [   24    70]]
    ------------------------------------------------------------
    Accuracy  : 0.9995259997893332
    Precision : 0.958904109589041
    Recall    : 0.7446808510638298
    F1-Score  : 0.8383233532934131
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.96      0.74      0.84        94

        accuracy                           1.00     56962
       macro avg       0.98      0.87      0.92     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.9757617117056447
    ================================================================================
    ================================================================================
    SMOTE
    ================================================================================
    0    227447
    1    227447
    Name: Class, dtype: int64
    ------------------------------
    0 비율 :  50.00 %
    1 비율 :  50.00 %
    ================================================================================
    CatBoost SMOTE
    ================================================================================
    Confusion Matrix
    [[56790    78]
     [   17    77]]
    ------------------------------------------------------------
    Accuracy  : 0.9983322214809873
    Precision : 0.4967741935483871
    Recall    : 0.8191489361702128
    F1-Score  : 0.6184738955823293
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.50      0.82      0.62        94

        accuracy                           1.00     56962
       macro avg       0.75      0.91      0.81     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.9760303442537328
    ================================================================================
    ================================================================================
    ADASYN
    ================================================================================
    1    227453
    0    227447
    Name: Class, dtype: int64
    ------------------------------
    1 비율 :  50.00 %
    0 비율 :  50.00 %
    ================================================================================
    CatBoost ADASYN
    ================================================================================
    Confusion Matrix
    [[56791    77]
     [   17    77]]
    ------------------------------------------------------------
    Accuracy  : 0.9983497770443454
    Precision : 0.5
    Recall    : 0.8191489361702128
    F1-Score  : 0.6209677419354839
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.50      0.82      0.62        94

        accuracy                           1.00     56962
       macro avg       0.75      0.91      0.81     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.9758747019974588
    ================================================================================
    ================================================================================
    SVMSMOTE
    ================================================================================
    0    227447
    1    227447
    Name: Class, dtype: int64
    ------------------------------
    0 비율 :  50.00 %
    1 비율 :  50.00 %
    ================================================================================
    CatBoost SVMSMOTE
    ================================================================================
    Confusion Matrix
    [[56841    27]
     [   17    77]]
    ------------------------------------------------------------
    Accuracy  : 0.9992275552122467
    Precision : 0.7403846153846154
    Recall    : 0.8191489361702128
    F1-Score  : 0.7777777777777779
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.74      0.82      0.78        94

        accuracy                           1.00     56962
       macro avg       0.87      0.91      0.89     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.9773693914537436
    ================================================================================
    ================================================================================
    CNN
    ================================================================================
    0    908
    1    398
    Name: Class, dtype: int64
    ------------------------------
    0 비율 :  69.53 %
    1 비율 :  30.47 %
    ================================================================================
    CatBoost CNN
    ================================================================================
    Confusion Matrix
    [[56860     8]
     [   18    76]]
    ------------------------------------------------------------
    Accuracy  : 0.9995435553526912
    Precision : 0.9047619047619048
    Recall    : 0.8085106382978723
    F1-Score  : 0.853932584269663
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.90      0.81      0.85        94

        accuracy                           1.00     56962
       macro avg       0.95      0.90      0.93     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.9759227789924858
    ================================================================================
    ================================================================================
    Near Miss 3
    ================================================================================
    1    398
    0    343
    Name: Class, dtype: int64
    ------------------------------
    1 비율 :  53.71 %
    0 비율 :  46.29 %
    ================================================================================
    CatBoost Near Miss 3
    ================================================================================
    Confusion Matrix
    [[56849    19]
     [   20    74]]
    ------------------------------------------------------------
    Accuracy  : 0.9993153330290369
    Precision : 0.7956989247311828
    Recall    : 0.7872340425531915
    F1-Score  : 0.7914438502673796
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.80      0.79      0.79        94

        accuracy                           1.00     56962
       macro avg       0.90      0.89      0.90     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.9304774850007258
    ================================================================================
    ================================================================================
    SMOTE + ENN
    ================================================================================
    1    227447
    0    227056
    Name: Class, dtype: int64
    ------------------------------
    1 비율 :  50.04 %
    0 비율 :  49.96 %
    ================================================================================
    CatBoost SMOTE + ENN
    ================================================================================
    Confusion Matrix
    [[56806    62]
     [   16    78]]
    ------------------------------------------------------------
    Accuracy  : 0.9986306660580738
    Precision : 0.5571428571428572
    Recall    : 0.8297872340425532
    F1-Score  : 0.6666666666666667
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.56      0.83      0.67        94

        accuracy                           1.00     56962
       macro avg       0.78      0.91      0.83     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.9794483005811143
    ================================================================================
    ================================================================================
    ADASYN + ENN
    ================================================================================
    1    227453
    0    227056
    Name: Class, dtype: int64
    ------------------------------
    1 비율 :  50.04 %
    0 비율 :  49.96 %
    ================================================================================
    CatBoost ADASYN + ENN
    ================================================================================
    Confusion Matrix
    [[56786    82]
     [   15    79]]
    ------------------------------------------------------------
    Accuracy  : 0.9982971103542713
    Precision : 0.4906832298136646
    Recall    : 0.8404255319148937
    F1-Score  : 0.6196078431372549
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.49      0.84      0.62        94

        accuracy                           1.00     56962
       macro avg       0.75      0.92      0.81     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.978338227085045
    ================================================================================
    ================================================================================
    SVMSMOTE + ENN
    ================================================================================
    1    227407
    0    227264
    Name: Class, dtype: int64
    ------------------------------
    1 비율 :  50.02 %
    0 비율 :  49.98 %
    ================================================================================
    CatBoost SVMSMOTE + ENN
    ================================================================================
    Confusion Matrix
    [[56835    33]
     [   17    77]]
    ------------------------------------------------------------
    Accuracy  : 0.9991222218320986
    Precision : 0.7
    Recall    : 0.8191489361702128
    F1-Score  : 0.7549019607843137
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.70      0.82      0.75        94

        accuracy                           1.00     56962
       macro avg       0.85      0.91      0.88     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.9626267773522559
    ================================================================================
    ================================================================================
    SMOTE + IHT
    ================================================================================
    0    227447
    1    227447
    Name: Class, dtype: int64
    ------------------------------
    0 비율 :  50.00 %
    1 비율 :  50.00 %
    ================================================================================
    CatBoost SMOTE + IHT
    ================================================================================
    Confusion Matrix
    [[56808    60]
     [   17    77]]
    ------------------------------------------------------------
    Accuracy  : 0.9986482216214319
    Precision : 0.5620437956204379
    Recall    : 0.8191489361702128
    F1-Score  : 0.6666666666666666
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.56      0.82      0.67        94

        accuracy                           1.00     56962
       macro avg       0.78      0.91      0.83     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.9806287124045382
    ================================================================================
    ================================================================================
    ADASYN + IHT
    ================================================================================
    0    227447
    1    227447
    Name: Class, dtype: int64
    ------------------------------
    0 비율 :  50.00 %
    1 비율 :  50.00 %
    ================================================================================
    CatBoost ADASYN + IHT
    ================================================================================
    Confusion Matrix
    [[56794    74]
     [   16    78]]
    ------------------------------------------------------------
    Accuracy  : 0.9984199992977775
    Precision : 0.5131578947368421
    Recall    : 0.8297872340425532
    F1-Score  : 0.6341463414634146
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.51      0.83      0.63        94

        accuracy                           1.00     56962
       macro avg       0.76      0.91      0.82     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.9794587765022097
    ================================================================================
    ================================================================================
    SVMSMOTE + IHT
    ================================================================================
    0    227447
    1    227447
    Name: Class, dtype: int64
    ------------------------------
    0 비율 :  50.00 %
    1 비율 :  50.00 %
    ================================================================================
    CatBoost SVMSMOTE + IHT
    ================================================================================
    Confusion Matrix
    [[56837    31]
     [   17    77]]
    ------------------------------------------------------------
    Accuracy  : 0.9991573329588147
    Precision : 0.7129629629629629
    Recall    : 0.8191489361702128
    F1-Score  : 0.7623762376237623
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.71      0.82      0.76        94

        accuracy                           1.00     56962
       macro avg       0.86      0.91      0.88     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.9735063955498287
    ================================================================================

<br>


### 가중치 부여


```python
class_weights = ['Balanced', 'SqrtBalanced']

for class_weight in class_weights:
    X, y = X_samples['Raw'], y_samples['Raw']

    print('=' * 80)
    print('Raw')
    show_data_info(y)

    clf = CatBoostClassifier(eval_metric='F1', auto_class_weights=class_weight,
                             early_stopping_rounds=100, verbose=False)
    clf.fit(X, y, eval_set=(X_test, y_test))

    print(f'CatBoost {class_weight}')
    result = evaluate_model(clf, X_test, y_test)

    clfs[class_weight] = clf
    results[class_weight] = result
```

    ================================================================================
    Raw
    ================================================================================
    0    227447
    1       398
    Name: Class, dtype: int64
    ------------------------------
    0 비율 :  99.83 %
    1 비율 :   0.17 %
    ================================================================================
    CatBoost Balanced
    ================================================================================
    Confusion Matrix
    [[54869  1999]
     [   10    84]]
    ------------------------------------------------------------
    Accuracy  : 0.9647308732137214
    Precision : 0.040326452232357174
    Recall    : 0.8936170212765957
    F1-Score  : 0.07717041800643086
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      0.96      0.98     56868
               1       0.04      0.89      0.08        94

        accuracy                           0.96     56962
       macro avg       0.52      0.93      0.53     56962
    weighted avg       1.00      0.96      0.98     56962

    ------------------------------------------------------------
    ROC AUC : 0.9736473528095672
    ================================================================================
    ================================================================================
    Raw
    ================================================================================
    0    227447
    1       398
    Name: Class, dtype: int64
    ------------------------------
    0 비율 :  99.83 %
    1 비율 :   0.17 %
    ================================================================================
    CatBoost SqrtBalanced
    ================================================================================
    Confusion Matrix
    [[56857    11]
     [   17    77]]
    ------------------------------------------------------------
    Accuracy  : 0.9995084442259752
    Precision : 0.875
    Recall    : 0.8191489361702128
    F1-Score  : 0.8461538461538463
    ------------------------------------------------------------
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00     56868
               1       0.88      0.82      0.85        94

        accuracy                           1.00     56962
       macro avg       0.94      0.91      0.92     56962
    weighted avg       1.00      1.00      1.00     56962

    ------------------------------------------------------------
    ROC AUC : 0.9835578547708093
    ================================================================================

<br>


## Results

```python
cols = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC_AUC']

evaluation = pd.DataFrame(results, index=cols)
evaluation
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Raw</th>
      <th>SMOTE</th>
      <th>ADASYN</th>
      <th>SVMSMOTE</th>
      <th>CNN</th>
      <th>Near Miss 3</th>
      <th>SMOTE + ENN</th>
      <th>ADASYN + ENN</th>
      <th>SVMSMOTE + ENN</th>
      <th>SMOTE + IHT</th>
      <th>ADASYN + IHT</th>
      <th>SVMSMOTE + IHT</th>
      <th>Balanced</th>
      <th>SqrtBalanced</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Accuracy</th>
      <td>0.999526</td>
      <td>0.998332</td>
      <td>0.998350</td>
      <td>0.999228</td>
      <td>0.999544</td>
      <td>0.999315</td>
      <td>0.998631</td>
      <td>0.998297</td>
      <td>0.999122</td>
      <td>0.998648</td>
      <td>0.998420</td>
      <td>0.999157</td>
      <td>0.964731</td>
      <td>0.999508</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.958904</td>
      <td>0.496774</td>
      <td>0.500000</td>
      <td>0.740385</td>
      <td>0.904762</td>
      <td>0.795699</td>
      <td>0.557143</td>
      <td>0.490683</td>
      <td>0.700000</td>
      <td>0.562044</td>
      <td>0.513158</td>
      <td>0.712963</td>
      <td>0.040326</td>
      <td>0.875000</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.744681</td>
      <td>0.819149</td>
      <td>0.819149</td>
      <td>0.819149</td>
      <td>0.808511</td>
      <td>0.787234</td>
      <td>0.829787</td>
      <td>0.840426</td>
      <td>0.819149</td>
      <td>0.819149</td>
      <td>0.829787</td>
      <td>0.819149</td>
      <td>0.893617</td>
      <td>0.819149</td>
    </tr>
    <tr>
      <th>F1-Score</th>
      <td>0.838323</td>
      <td>0.618474</td>
      <td>0.620968</td>
      <td>0.777778</td>
      <td>0.853933</td>
      <td>0.791444</td>
      <td>0.666667</td>
      <td>0.619608</td>
      <td>0.754902</td>
      <td>0.666667</td>
      <td>0.634146</td>
      <td>0.762376</td>
      <td>0.077170</td>
      <td>0.846154</td>
    </tr>
    <tr>
      <th>ROC_AUC</th>
      <td>0.975762</td>
      <td>0.976030</td>
      <td>0.975875</td>
      <td>0.977369</td>
      <td>0.975923</td>
      <td>0.930477</td>
      <td>0.979448</td>
      <td>0.978338</td>
      <td>0.962627</td>
      <td>0.980629</td>
      <td>0.979459</td>
      <td>0.973506</td>
      <td>0.973647</td>
      <td>0.983558</td>
    </tr>
  </tbody>
</table>


```python
evaluation.plot(kind="bar", figsize=(15, 5), width=0.9, rot=0)
plt.legend(loc=(1.01, 0.))
plt.show()
```

![output](/assets/images/post/2021-03-05-output_13_0.png)

<br>

> 참고 : 하이퍼 파라미터 튜닝을 하지 않은 LightGBM (dart 모드)의 결과
>
> ![output](/assets/images/post/2021-03-05-output_LightGBM.png){: style="background-color: #888;"}
